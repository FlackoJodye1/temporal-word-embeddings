{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from scipy import spatial\n",
    "import scipy.sparse as sp\n",
    "from tqdm.notebook import tqdm\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from src.packages.TPPMI.ppmi_model import PPMIModel\n",
    "from src.packages.TPPMI.tppmi_model import TPPMIModel"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_test_data = Path(\"../../data\") / \"test\"\n",
    "path_to_tppmi_model = Path(\"../../data\") / \"ppmi-matrices\" / \"nyt-data\"\n",
    "path_to_twec_model = Path(\"../../model\") / \"nyt-data\" / \"cade\" / \"model\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testset 1\n",
    "\n",
    "Based on publicly recorded knowledge that for each year lists different names for a particular role, such as U.S. president, U.K. prime minister, NFL superbowl champion team, and so on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_1 = pd.read_csv(path_to_test_data / \"testset_1.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_1.columns = ['truth', 'equivalent']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_cases_1 = test_data_1['truth'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Testset1 contains {len(test_cases_1)} test cases\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testset 2\n",
    "\n",
    "Testset 2 is human-generated, for exploring more interesting concepts like emerging technologies, brands and major events (e.g., disease outbreaks and financial crisis). For constructing the test word pairs, we first select emerging terms which have not been popularized before 1994, then query their well known precedents during 1990 to 1994 (e.g., app-2012 can correspond to software-1990)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_2 = pd.read_csv(path_to_test_data / \"testset_2.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_2.columns = ['truth', 'equivalent']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_2.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TWEC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cade_model_filenames = glob(str(path_to_twec_model / \"*.model\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load models\n",
    "cade_models = {f\"model_{model_file.split('_data')[0][-4:]}\":Word2Vec.load(model_file) for model_file in tqdm(cade_model_filenames)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cade_models.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testset 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_1 = dict()\n",
    "counter = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(test_cases_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for test_case in test_cases_1:\n",
    "    word, year = test_case.split(\"-\")\n",
    "    ground_model = cade_models[f\"model_{year}\"]\n",
    "    if word in ground_model.wv.vocab:\n",
    "        test_case_dict_1[test_case] = ground_model.wv.get_vector(word)\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "print(counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cade_model = cade_models[next(iter(cade_models))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_similarities_of_model(model, test_word, top_n = 10):\n",
    "    # Compute cosine similarity between specified embedding and all embeddings in the model\n",
    "    test_word_embedding = test_word[1]\n",
    "    test_word_key = test_word[0]\n",
    "    word_similarities = dict()\n",
    "    for reference_word in model.wv.vocab:\n",
    "        reference_word_embedding = model.wv[reference_word]\n",
    "        similarity = 1 - spatial.distance.cosine(test_word_embedding, reference_word_embedding)\n",
    "        word_similarities[word] = similarity\n",
    "\n",
    "    # Sort words by similarity\n",
    "    sorted_similarities = sorted(word_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Get top_n similar words\n",
    "    return sorted_similarities[:top_n]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_similarities_of_models(model_dict: dict, test_word_dict: dict):\n",
    "    similarities = dict()\n",
    "    for test_word in test_word_dict.items():\n",
    "        similarities[test_word[0]] = dict()\n",
    "        '''print(test_word)\n",
    "        print(type(test_word))'''\n",
    "        for model in model_dict.items():\n",
    "            '''print(model)\n",
    "            print(type(model))\n",
    "            print(model[0])'''\n",
    "            similarities[test_word[0]][model[0].split(\"_\")[1]] = get_similarities_of_model(model[1], test_word)\n",
    "    return similarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarities = get_similarities_of_models(cade_models, test_case_dict_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cade_models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_similarities_of_models(cade_models, test_case_dict_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute cosine similarity between specified embedding and all embeddings in the model\n",
    "word_similarities = {}\n",
    "for word in cade_model.wv.vocab:\n",
    "    word_embedding = cade_model.wv[word]\n",
    "    similarity = 1 - spatial.distance.cosine(test_case_dict_1[next(iter(test_case_dict_1))], word_embedding)\n",
    "    word_similarities[word] = similarity\n",
    "\n",
    "# Sort words by similarity\n",
    "sorted_similarities = sorted(word_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Get top N similar words\n",
    "top_n = 10  # or any number you prefer\n",
    "most_similar_words = sorted_similarities[:top_n]\n",
    "\n",
    "for word, similarity in most_similar_words:\n",
    "    print(f\"{word}: {similarity}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cade_model.wv.most_similar()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TPPMI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ppmi_data_files = sorted(glob(str(path_to_tppmi_model  / \"*.npz\")))\n",
    "words_files = sorted(glob(str(path_to_tppmi_model  / \"*.pkl\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split context-words from timestamped-vocabularies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "context_words_file = [path for path in words_files if \"context-words\" in path]\n",
    "ppmi_vocab_files = [path for path in words_files if \"context-words\" not in path]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get ppmi-matrices and vocab\n",
    "ppmi_matrices = {}\n",
    "\n",
    "for filenames in zip(ppmi_vocab_files, ppmi_data_files):\n",
    "    ppmi_matrix = sp.load_npz(filenames[1])\n",
    "    with open(filenames[0], \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    key = filenames[0].split(\"ppmi-\")[2][0:4]\n",
    "    ppmi_matrices[key] = {\"ppmi_matrix\" : ppmi_matrix, \"vocab\": vocab}\n",
    "\n",
    "# Get common context-words\n",
    "with open(context_words_file[0], \"rb\") as f:\n",
    "    context_words = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ppmi_matrices.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create ppmi_model objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ppmi_models = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words) for key, ppmi_data in ppmi_matrices.items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tppmi_model = TPPMIModel(ppmi_models, dates=\"years\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation Method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MRR (Mean Reciprocal Rank)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To examine the quality of embedding alignment, we create a task to query equivalences across years.\n",
    "\n",
    "For example, given obama-2012, we want to query its equivalent word in 2002. As we know obama is the U.S. president in 2012; its equivalent in 2002 is bush, who was the U.S. president at that time. In this way, we create two testsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_1.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
