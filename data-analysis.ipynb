{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data-Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read data from processed csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DIR = Path(\"data\")\n",
    "split_dir = DIR / \"split\"\n",
    "sub_dir = \"monthly\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if sub_dir:\n",
    "    csv_files = glob.glob(str(split_dir / sub_dir / \"*.csv\"))\n",
    "else:\n",
    "    csv_files = glob.glob(str(split_dir / \"*/*.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# used for training the Cade-Compass\n",
    "df_all = pd.concat(dataframes, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Imported {len(dataframes)} files\")\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"Data from Period {i+1}: {df.date.min()} - {df.date.max()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert date back to datetime object and sort them by date\n",
    "for df in dataframes:\n",
    "    df['date'] =  pd.to_datetime(df['date'])\n",
    "    df.sort_values('date', inplace=True)\n",
    "\n",
    "df_all['date'] =  pd.to_datetime(df_all['date'])\n",
    "df_all.sort_values('date', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if any missing values are in the (processed) text column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all[\"text\"].isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If there are any but still amount to only an insignificant portion of the data, we delete them as to not cause problems with nltk's tokenizers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all.dropna(subset=['text'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample-Engine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***CBS-News - The Hottest Topic of each Month:***\n",
    "\n",
    "***2022***\n",
    "* Roe / Wade / Abortion (June)\n",
    "* Shinzo / Abe / Japan(July)\n",
    "* Trump / Mar-a-Lago (August)\n",
    "* Queen / Elizabeth / England (September)\n",
    "* Elon / Musk / Twitter (October)\n",
    "* Republicans / Red / Wave (November)\n",
    "* Russia / Brittney / Griner / Prisoner (December)\n",
    "\n",
    "***2023 (TODO)***\n",
    "* xxx (January)\n",
    "* xxx (February)\n",
    "* xxx (March)\n",
    "* xxx (April)\n",
    "\n",
    "Timeframe: 2022-06-01 to 2023-04-28\n",
    "source: [cbsnews](https://www.cbsnews.com/news/the-year-in-review-top-news-stories-of-2022-month-by-month/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_text(df, month = \"06\"):\n",
    "    sample_stream_1 = df.sample(1)\n",
    "    print(\"Stream 1\")\n",
    "    print(f\"Date: {sample_stream_1['date'].iloc[0].date()}\")\n",
    "    print(f\"Sentiment: {sample_stream_1['sentiment'].iloc[0]}\")\n",
    "    print(\"----------------\")\n",
    "    print(sample_stream_1[\"text\"].iloc[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notable Events:\n",
    "\n",
    "* Teacherstrike"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_text(df_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Corpora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_all = df_all[\"text\"].values.tolist()\n",
    "\n",
    "corpora = [df[\"text\"].values.tolist() for df in dataframes]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "tokens_all = tokenizer.tokenize(\" \".join(str(text) for text in tqdm(corpus_all)))\n",
    "\n",
    "tokens = [tokenizer.tokenize(\" \".join(str(text) for text in corpus)) for corpus in tqdm(corpora)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Vocabularies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# unique vocabulary of each class\n",
    "vocabulary_all = set(tokens_all)\n",
    "\n",
    "vocabularies = [set(tokens_split) for tokens_split in tqdm(tokens)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vocabulary_size_all = len(vocabulary_all)\n",
    "\n",
    "vocabulary_sizes = [len(vocabulary) for vocabulary in vocabularies]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens[0].count(\"pelosis\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Vocabulary size: {vocabulary_size_all}\")\n",
    "for i, vocab_size in enumerate(vocabulary_sizes):\n",
    "    print(f\"Vocabulary size of split {i+1}: {vocab_size}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Static: Word2Vec (Gensim)\n",
    "\n",
    "2. Temporal: TWEC/CADE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Word2Vec (static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "tokenized_sentences_all = [word_tokenize(item) for item in tqdm(corpus_all)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(tokenized_sentences_all, min_count = 1, seed=1040)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_word = \"trump\"\n",
    "w2v_model.wv.most_similar(test_word)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_model.save(\"model/static/word2vec.model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Temporal: TWEC/CADE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Temporal Word Embeddings with a Compass***\n",
    "\n",
    "* [Source-Code](https://github.com/valedica/twec)\n",
    "\n",
    "* [Paper](https://arxiv.org/abs/1906.02376)\n",
    "\n",
    "* [Blogpost](https://fede-bianchi.medium.com/aligning-temporal-diachronic-word-embeddings-with-a-compass-732ab7427955)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the concatenated text to txt-files to make them usable for Cade"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cade.cade import CADE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cade_dir = DIR / \"cade\"\n",
    "cade_split_dir = cade_dir / sub_dir\n",
    "cade_split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_paths = [(cade_split_dir / csv_file.split(\"/\")[-1].split(\".\")[0]).with_suffix(\".txt\") for csv_file in csv_files]\n",
    "\n",
    "file_paths_and_corpora = {\n",
    "    cade_dir / 'compass.txt': corpus_all\n",
    "}\n",
    "\n",
    "for key, value in zip(file_paths, corpora):\n",
    "    file_paths_and_corpora[key] = value\n",
    "\n",
    "for file_path, corpus in file_paths_and_corpora.items():\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in corpus:\n",
    "            file.write(\"%s\\n\" % item)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# only needed once for the installation & creation of a venv\n",
    "'''%%capture\n",
    "!pip install -U cade\n",
    "!pip install git+https://github.com/vinid/gensim.git''';"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create & train the compass\n",
    "\n",
    "This creates atemporal context and target word embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "aligner = CADE(size=30, min_count = 1)\n",
    "aligner.train_compass(str((cade_dir / \"compass\").with_suffix(\".txt\")), overwrite=True);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# train slices, they will be already aligned\n",
    "slices = [aligner.train_slice(file_path, save=True) for file_path in file_paths] # list of gensim word2vec objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
