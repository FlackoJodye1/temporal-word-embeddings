{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import scipy.sparse as sp\n",
    "from tqdm.notebook import tqdm\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import src.test.util as test_util"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_to_test_data = Path(\"../../data\") / \"test\"\n",
    "path_to_tppmi_model = Path(\"../../data\") / \"ppmi-matrices\" / \"nyt-data\"\n",
    "path_to_twec_model = Path(\"../../model\") / \"nyt-data\" / \"cade\" / \"model\"\n",
    "path_to_static_model = Path(\"../../model\") / \"nyt-data\" / \"static\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testset 1\n",
    "\n",
    "Based on publicly recorded knowledge that for each year lists different names for a particular role, such as U.S. president, U.K. prime minister, NFL superbowl champion team, and so on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path_to_test_data / \"testset_1_enriched.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "        truth     equivalent   word      tag\n0  49ers-1990  patriots-2015  49ers  unknown\n1  49ers-1990   cowboys-1993  49ers  unknown\n2  49ers-1990   cowboys-1994  49ers  unknown\n3  49ers-1990     49ers-1995  49ers  unknown\n4  49ers-1990   cowboys-1996  49ers  unknown",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>truth</th>\n      <th>equivalent</th>\n      <th>word</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49ers-1990</td>\n      <td>patriots-2015</td>\n      <td>49ers</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49ers-1990</td>\n      <td>cowboys-1993</td>\n      <td>49ers</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49ers-1990</td>\n      <td>cowboys-1994</td>\n      <td>49ers</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49ers-1990</td>\n      <td>49ers-1995</td>\n      <td>49ers</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49ers-1990</td>\n      <td>cowboys-1996</td>\n      <td>49ers</td>\n      <td>unknown</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "test_data.columns = ['truth', 'equivalent', 'word', 'tag']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "test_data = test_data.sort_values(by='truth', ascending=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "test_cases = test_data['truth'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset\n",
      "Testcases (all): 606729\n",
      "Testcases (unique): 499\n"
     ]
    }
   ],
   "source": [
    "print(\"Testset\")\n",
    "print(f\"Testcases (all): {len(test_data)}\")\n",
    "print(f\"Testcases (unique): {len(test_cases)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we want to split the testset into static & dynamic testcases as was done by Di Carlo et al. in their paper \"Training Temporal Word Embeddings with a Compass\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Splitting the columns into words and years\n",
    "split_truth = test_data['truth'].str.split('-', expand=True)\n",
    "split_equivalent = test_data['equivalent'].str.split('-', expand=True)\n",
    "\n",
    "# Creating masks for \"static\" and \"dynamic\" conditions\n",
    "static_mask = split_truth[0] == split_equivalent[0]\n",
    "dynamic_mask = split_truth[0] != split_equivalent[0]\n",
    "\n",
    "# Applying the masks to create the separate DataFrames\n",
    "test_data_1_static = test_data[static_mask]\n",
    "test_data_1_dynamic = test_data[dynamic_mask]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "test_cases_1_static = test_data_1_static['truth'].unique()\n",
    "test_cases_1_dynamic = test_data_1_dynamic['truth'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static\n",
      "Testcases (all): 203504\n",
      "Testcases (unique): 443\n"
     ]
    }
   ],
   "source": [
    "print(\"Static\")\n",
    "print(f\"Testcases (all): {len(test_data_1_static)}\")\n",
    "print(f\"Testcases (unique): {len(test_cases_1_static)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic\n",
      "Testcases (all): 403225\n",
      "Testcases (unique): 499\n"
     ]
    }
   ],
   "source": [
    "print(\"Dynamic\")\n",
    "print(f\"Testcases (all): {len(test_data_1_dynamic)}\")\n",
    "print(f\"Testcases (unique): {len(test_cases_1_dynamic)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TWEC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model_filenames_cade = glob(str(path_to_twec_model / \"*_data.model\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b60c2a1aa54f2990fa14238fcf5706"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load models\n",
    "models_cade = {f\"model_{model_file.split('_data')[0][-4:]}\":Word2Vec.load(model_file) for model_file in tqdm(model_filenames_cade)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "models_cade = {model_key: models_cade[model_key] for model_key in sorted(models_cade, key=lambda x: int(x.split('_')[1]))}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['model_1990', 'model_1991', 'model_1992', 'model_1993', 'model_1994', 'model_1995', 'model_1996', 'model_1997', 'model_1998', 'model_1999', 'model_2000', 'model_2001', 'model_2002', 'model_2003', 'model_2004', 'model_2005', 'model_2006', 'model_2007', 'model_2008', 'model_2009', 'model_2010', 'model_2011', 'model_2012', 'model_2013', 'model_2014', 'model_2015', 'model_2016'])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_cade.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create dictionary of testsets that contain all test-words along with their embedding in the respective year"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Testcases are not in the vocab of the model(s)\n"
     ]
    }
   ],
   "source": [
    "test_case_dict_cade_all = test_util.create_test_case_dict_cade(test_cases, models_cade)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Testcases are not in the vocab of the model(s)\n"
     ]
    }
   ],
   "source": [
    "test_case_dict_cade_static = test_util.create_test_case_dict_cade(test_cases_1_static, models_cade)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Testcases are not in the vocab of the model(s)\n"
     ]
    }
   ],
   "source": [
    "test_case_dict_cade_dynamic = test_util.create_test_case_dict_cade(test_cases_1_dynamic, models_cade)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve most similar words for each testword in each year"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bb8122f963340dbb28ee924a6c7d39f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_cade_all = test_util.get_similarities_of_models(models_cade, test_case_dict_cade_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/441 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e45f7bf4695342a3b688d838f29b4071"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_cade_static = test_util.get_similarities_of_models(models_cade, test_case_dict_cade_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "037f472bb40e42c58f6ff0284d58f989"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_cade_dynamic = test_util.get_similarities_of_models(models_cade, test_case_dict_cade_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Static Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "model_static = Word2Vec.load(str(path_to_static_model / \"w2v_model.model\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Testcases are not in the vocab of the model\n"
     ]
    }
   ],
   "source": [
    "test_case_dict_static_all = test_util.create_test_case_dict_static(model_static, test_cases)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Testcases are not in the vocab of the model\n"
     ]
    }
   ],
   "source": [
    "test_case_dict_static_static = test_util.create_test_case_dict_static(model_static, test_cases_1_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Testcases are not in the vocab of the model\n"
     ]
    }
   ],
   "source": [
    "test_case_dict_static_dynamic = test_util.create_test_case_dict_static(model_static, test_cases_1_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/499 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2723b21ee9784885a21929ea759f5c3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_static_all = test_util.get_similarities_of_models_static(model_static, test_case_dict_static_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/443 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7b9137f65c14b30830962cd5da31ab0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_static_static = test_util.get_similarities_of_models_static(model_static, test_case_dict_static_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/499 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6728acfc8911415a85532a1a395fdb21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_static_dynamic = test_util.get_similarities_of_models_static(model_static, test_case_dict_static_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TPPMI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from src.packages.TPPMI.ppmi_model import PPMIModel\n",
    "from src.packages.TPPMI.tppmi_model import TPPMIModel\n",
    "import src.test.util as test_util"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "sub_dirs = [\"500\", \"1000\", \"2000\", \"4000\", \"6000\"] # each dir stores ppmi-data with the respective number of context words\n",
    "\n",
    "# Collecting .npz files\n",
    "ppmi_data_files = sorted([file for dir in sub_dirs\n",
    "                          for file in glob(str(path_to_tppmi_model / dir / \"*.npz\"))])\n",
    "\n",
    "# Collecting .pkl files\n",
    "words_files = sorted([file for dir in sub_dirs\n",
    "                      for file in glob(str(path_to_tppmi_model / dir / \"*.pkl\"))])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split context-words from timestamped-vocabularies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "context_words_files = [path for path in words_files if \"context-words\" in path]\n",
    "ppmi_vocab_files = [path for path in words_files if \"context-words\" not in path]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/ppmi-matrices/nyt-data/1000/context-words.pkl\n",
      "../../data/ppmi-matrices/nyt-data/2000/context-words.pkl\n",
      "../../data/ppmi-matrices/nyt-data/4000/context-words.pkl\n",
      "../../data/ppmi-matrices/nyt-data/500/context-words.pkl\n",
      "../../data/ppmi-matrices/nyt-data/6000/context-words.pkl\n"
     ]
    }
   ],
   "source": [
    "for context_words_file in context_words_files:\n",
    "    print(context_words_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Get ppmi-matrices and vocab\n",
    "ppmi_matrices_500 = {}\n",
    "ppmi_matrices_1000 = {}\n",
    "ppmi_matrices_2000 = {}\n",
    "ppmi_matrices_4000 = {}\n",
    "ppmi_matrices_6000 = {}\n",
    "\n",
    "for filenames in zip(ppmi_vocab_files, ppmi_data_files):\n",
    "    ppmi_matrix = sp.load_npz(filenames[1])\n",
    "    with open(filenames[0], \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    key = filenames[0].split(\"ppmi-\")[2][0:4]\n",
    "    if \"500\" in filenames[0] and \"500\" in filenames[1]:\n",
    "        ppmi_matrices_500[key] = {\"ppmi_matrix\" : ppmi_matrix, \"vocab\": vocab}\n",
    "    elif \"1000\" in filenames[0] and \"1000\" in filenames[1]:\n",
    "        ppmi_matrices_1000[key] = {\"ppmi_matrix\" : ppmi_matrix, \"vocab\": vocab}\n",
    "    elif \"4000\" in filenames[0] and \"4000\" in filenames[1]:\n",
    "        ppmi_matrices_4000[key] = {\"ppmi_matrix\" : ppmi_matrix, \"vocab\": vocab}\n",
    "    elif \"6000\" in filenames[0] and \"6000\" in filenames[1]:\n",
    "        ppmi_matrices_6000[key] = {\"ppmi_matrix\" : ppmi_matrix, \"vocab\": vocab}\n",
    "    else:\n",
    "        ppmi_matrices_2000[key] = {\"ppmi_matrix\" : ppmi_matrix, \"vocab\": vocab}\n",
    "\n",
    "# Get common context-words\n",
    "for context_words_file in context_words_files:\n",
    "    with open(context_words_file, \"rb\") as f:\n",
    "        if \"500\" in str(context_words_file):\n",
    "            context_words_500 = pickle.load(f)\n",
    "        elif \"1000\" in str(context_words_file):\n",
    "            context_words_1000 = pickle.load(f)\n",
    "        elif \"4000\" in str(context_words_file):\n",
    "            context_words_4000 = pickle.load(f)\n",
    "        elif \"6000\" in str(context_words_file):\n",
    "            context_words_6000 = pickle.load(f)\n",
    "        else:\n",
    "            context_words_2000 = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016'])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi_matrices_500.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create ppmi_model objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[36], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m ppmi_models_1000 \u001B[38;5;241m=\u001B[39m {key: PPMIModel\u001B[38;5;241m.\u001B[39mconstruct_from_data(ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mppmi_matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m], ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvocab\u001B[39m\u001B[38;5;124m\"\u001B[39m], context_words_1000, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m key, ppmi_data \u001B[38;5;129;01min\u001B[39;00m ppmi_matrices_1000\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m----> 5\u001B[0m ppmi_models_2000 \u001B[38;5;241m=\u001B[39m {key: PPMIModel\u001B[38;5;241m.\u001B[39mconstruct_from_data(ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mppmi_matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m], ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvocab\u001B[39m\u001B[38;5;124m\"\u001B[39m], context_words_2000, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m key, ppmi_data \u001B[38;5;129;01min\u001B[39;00m ppmi_matrices_2000\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03mppmi_models_4000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_4000, normalize=True) for key, ppmi_data in ppmi_matrices_4000.items()}\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03mppmi_models_6000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_6000, normalize=True) for key, ppmi_data in ppmi_matrices_6000.items()}'''\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[36], line 5\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      3\u001B[0m ppmi_models_1000 \u001B[38;5;241m=\u001B[39m {key: PPMIModel\u001B[38;5;241m.\u001B[39mconstruct_from_data(ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mppmi_matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m], ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvocab\u001B[39m\u001B[38;5;124m\"\u001B[39m], context_words_1000, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m key, ppmi_data \u001B[38;5;129;01min\u001B[39;00m ppmi_matrices_1000\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m----> 5\u001B[0m ppmi_models_2000 \u001B[38;5;241m=\u001B[39m {key: PPMIModel\u001B[38;5;241m.\u001B[39mconstruct_from_data(ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mppmi_matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m], ppmi_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvocab\u001B[39m\u001B[38;5;124m\"\u001B[39m], context_words_2000, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m key, ppmi_data \u001B[38;5;129;01min\u001B[39;00m ppmi_matrices_2000\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03mppmi_models_4000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_4000, normalize=True) for key, ppmi_data in ppmi_matrices_4000.items()}\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03mppmi_models_6000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_6000, normalize=True) for key, ppmi_data in ppmi_matrices_6000.items()}'''\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/temporal-word-embeddings/notebooks/analysis-quantitative/../../src/packages/TPPMI/ppmi_model.py:80\u001B[0m, in \u001B[0;36mPPMIModel.construct_from_data\u001B[0;34m(cls, ppmi_matrix, vocab, context_words, min_freq, normalize)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m\"\"\"Construct PPMIModel from precomputed PPMI matrix (DataFrame).\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \n\u001B[1;32m     72\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;124;03m    :param ppmi_matrix:\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m---> 80\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, context_words, min_freq, ppmi_matrix, vocab, normalize\u001B[38;5;241m=\u001B[39mnormalize)\n",
      "File \u001B[0;32m~/DataspellProjects/temporal-word-embeddings/notebooks/analysis-quantitative/../../src/packages/TPPMI/ppmi_model.py:62\u001B[0m, in \u001B[0;36mPPMIModel.__init__\u001B[0;34m(self, text_df, context_words, min_freq, ppmi_matrix, vocab, normalize)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m normalize:\n\u001B[0;32m---> 62\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_l2_normalize()\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ppmi_matrix_exists \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/temporal-word-embeddings/notebooks/analysis-quantitative/../../src/packages/TPPMI/ppmi_model.py:407\u001B[0m, in \u001B[0;36mPPMIModel._l2_normalize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_l2_normalize\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 407\u001B[0m     norms \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mppmi_matrix, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    408\u001B[0m     norms[norms \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m  \u001B[38;5;66;03m# Avoid division by zero\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/analysis-test/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583\u001B[0m, in \u001B[0;36mnorm\u001B[0;34m(x, ord, axis, keepdims)\u001B[0m\n\u001B[1;32m   2582\u001B[0m     s \u001B[38;5;241m=\u001B[39m (x\u001B[38;5;241m.\u001B[39mconj() \u001B[38;5;241m*\u001B[39m x)\u001B[38;5;241m.\u001B[39mreal\n\u001B[0;32m-> 2583\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m sqrt(add\u001B[38;5;241m.\u001B[39mreduce(s, axis\u001B[38;5;241m=\u001B[39maxis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims))\n\u001B[1;32m   2584\u001B[0m \u001B[38;5;66;03m# None of the str-type keywords for ord ('fro', 'nuc')\u001B[39;00m\n\u001B[1;32m   2585\u001B[0m \u001B[38;5;66;03m# are valid for vectors\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/miniforge3/envs/analysis-test/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3547\u001B[0m, in \u001B[0;36mInteractiveShell.run_code\u001B[0;34m(self, code_obj, result, async_)\u001B[0m\n\u001B[1;32m   3545\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m   3546\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 3547\u001B[0m         result\u001B[38;5;241m.\u001B[39merror_in_exec \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mexc_info()[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3548\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshowtraceback(running_compiled_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   3549\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ppmi_models_500 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_500, normalize=True) for key, ppmi_data in ppmi_matrices_500.items()}\n",
    "\n",
    "ppmi_models_1000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_1000, normalize=True) for key, ppmi_data in ppmi_matrices_1000.items()}\n",
    "\n",
    "ppmi_models_2000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_2000, normalize=True) for key, ppmi_data in ppmi_matrices_2000.items()}\n",
    "\n",
    "'''\n",
    "ppmi_models_4000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_4000, normalize=True) for key, ppmi_data in ppmi_matrices_4000.items()}\n",
    "\n",
    "ppmi_models_6000 = {key: PPMIModel.construct_from_data(ppmi_data[\"ppmi_matrix\"], ppmi_data[\"vocab\"], context_words_6000, normalize=True) for key, ppmi_data in ppmi_matrices_6000.items()}''';"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tppmi_model_500 = TPPMIModel(ppmi_models_500, dates=\"years\", smooth=False)\n",
    "tppmi_model_1000 = TPPMIModel(ppmi_models_1000, dates=\"years\", smooth=False)\n",
    "tppmi_model_2000 = TPPMIModel(ppmi_models_2000, dates=\"years\", smooth=False)\n",
    "\n",
    "# bigger models\n",
    "# tppmi_model_4000 = TPPMIModel(ppmi_models_4000, dates=\"years\", smooth=False)\n",
    "# tppmi_model_6000 = TPPMIModel(ppmi_models_6000, dates=\"years\", smooth=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create test-dictionaries for all test cases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_500_all = test_util.create_test_case_dict_tppmi(tppmi_model_500, test_cases_1_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_1000_all = test_util.create_test_case_dict_tppmi(tppmi_model_1000, test_cases_1_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_2000_all = test_util.create_test_case_dict_tppmi(tppmi_model_2000, test_cases_1_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bigger models:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_case_dict_tppmi_4000_all = test_util.create_test_case_dict_tppmi(tppmi_model_4000, test_cases_1_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test_case_dict_tppmi_6000_all = test_util.create_test_case_dict_tppmi(tppmi_model_6000, test_cases_1_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create test-dictionaries for static test cases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_500_static = test_util.create_test_case_dict_tppmi(tppmi_model_500, test_cases_1_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_1000_static = test_util.create_test_case_dict_tppmi(tppmi_model_1000, test_cases_1_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_2000_static = test_util.create_test_case_dict_tppmi(tppmi_model_2000, test_cases_1_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_case_dict_tppmi_4000_static = test_util.create_test_case_dict_tppmi(tppmi_model_4000, test_cases_1_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_case_dict_tppmi_6000_static = test_util.create_test_case_dict_tppmi(tppmi_model_6000, test_cases_1_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create test-dictionaries for dynamic test cases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_500_dynamic = test_util.create_test_case_dict_tppmi(tppmi_model_500, test_cases_1_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_1000_dynamic = test_util.create_test_case_dict_tppmi(tppmi_model_1000, test_cases_1_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_dict_tppmi_2000_dynamic = test_util.create_test_case_dict_tppmi(tppmi_model_2000, test_cases_1_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_case_dict_tppmi_4000_dynamic = test_util.create_test_case_dict_tppmi(tppmi_model_4000, test_cases_1_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_case_dict_tppmi_6000_dynamic = test_util.create_test_case_dict_tppmi(tppmi_model_6000, test_cases_1_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculate similarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate similarities for all testcases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/480 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1708ba3e8844045baa6e0f7d3f2105e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_tppmi_500_all = test_util.get_similarites_of_models_tppmi(tppmi_model_500, test_case_dict_tppmi_500_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/480 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67f2a80c552f4d51883b767ed6e52132"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_tppmi_1000_all = test_util.get_similarites_of_models_tppmi(tppmi_model_1000, test_case_dict_tppmi_1000_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/480 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69a86b5a6c7d4c379ae132aea698c3e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m similarities_tppmi_2000_all \u001B[38;5;241m=\u001B[39m test_util\u001B[38;5;241m.\u001B[39mget_similarites_of_models_tppmi(tppmi_model_2000, test_case_dict_tppmi_2000_all)\n",
      "File \u001B[0;32m~/DataspellProjects/temporal-word-embeddings/notebooks/analysis-quantitative/../../src/test/util.py:184\u001B[0m, in \u001B[0;36mget_similarites_of_models_tppmi\u001B[0;34m(model, test_word_dict)\u001B[0m\n\u001B[1;32m    182\u001B[0m similarities \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m word, vector \u001B[38;5;129;01min\u001B[39;00m tqdm(test_word_dict\u001B[38;5;241m.\u001B[39mitems()):\n\u001B[0;32m--> 184\u001B[0m     similarities[word] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mmost_similar_words_by_vector(vector)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m similarities\n",
      "File \u001B[0;32m~/DataspellProjects/temporal-word-embeddings/notebooks/analysis-quantitative/../../src/packages/TPPMI/tppmi_model.py:321\u001B[0m, in \u001B[0;36mTPPMIModel.most_similar_words_by_vector\u001B[0;34m(self, target_vector, top_n)\u001B[0m\n\u001B[1;32m    318\u001B[0m similar_words \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m date, model \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mppmi_models\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 321\u001B[0m     similar_words[date] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mmost_similar_words_by_vector(target_vector, top_n)\n\u001B[1;32m    323\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m similar_words\n",
      "File \u001B[0;32m~/DataspellProjects/temporal-word-embeddings/notebooks/analysis-quantitative/../../src/packages/TPPMI/ppmi_model.py:256\u001B[0m, in \u001B[0;36mPPMIModel.most_similar_words_by_vector\u001B[0;34m(self, vector, top_n)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;124;03mvector = vector.flatten()\u001B[39;00m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;124;03mif vector.ndim == 1:\u001B[39;00m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;124;03m    vector = vector.reshape(1, -1)'''\u001B[39;00m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;66;03m# Compute cosine similarities in a batch operation\u001B[39;00m\n\u001B[0;32m--> 256\u001B[0m similarities \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mppmi_matrix, vector\u001B[38;5;241m.\u001B[39mT)\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[1;32m    258\u001B[0m \u001B[38;5;66;03m# Get the indices of the top_n most similar words\u001B[39;00m\n\u001B[1;32m    259\u001B[0m top_indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(\u001B[38;5;241m-\u001B[39msimilarities)[:top_n]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "similarities_tppmi_2000_all = test_util.get_similarites_of_models_tppmi(tppmi_model_2000, test_case_dict_tppmi_2000_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# similarities_tppmi_4000_all = test_util.get_similarites_of_models_tppmi(tppmi_model_4000, test_case_dict_tppmi_4000_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# similarities_tppmi_6000_all = test_util.get_similarites_of_models_tppmi(tppmi_model_6000, test_case_dict_tppmi_6000_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate similarities for static testcases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarities_tppmi_500_static = test_util.get_similarites_of_models_tppmi(tppmi_model_500, test_case_dict_tppmi_500_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarities_tppmi_1000_static = test_util.get_similarites_of_models_tppmi(tppmi_model_1000, test_case_dict_tppmi_1000_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarities_tppmi_2000_static = test_util.get_similarites_of_models_tppmi(tppmi_model_2000, test_case_dict_tppmi_2000_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "similarities_tppmi_4000_static = test_util.get_similarites_of_models_tppmi(tppmi_model_4000, test_case_dict_tppmi_4000_static)''';"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "similarities_tppmi_6000_static = test_util.get_similarites_of_models_tppmi(tppmi_model_6000, test_case_dict_tppmi_6000_static)\n",
    "''';"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate similarities for dynamic testcases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarities_tppmi_500_dynamic = test_util.get_similarites_of_models_tppmi(tppmi_model_500, test_case_dict_tppmi_500_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarities_tppmi_1000_dynamic = test_util.get_similarites_of_models_tppmi(tppmi_model_1000, test_case_dict_tppmi_1000_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarities_tppmi_2000_dynamic = test_util.get_similarites_of_models_tppmi(tppmi_model_2000, test_case_dict_tppmi_2000_dynamic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "similarities_tppmi_4000_dynamic = test_util.get_similarites_of_models_tppmi(tppmi_model_4000, test_case_dict_tppmi_4000_dynamic)\n",
    "''';"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "similarities_tppmi_6000_dynamic = test_util.get_similarites_of_models_tppmi(tppmi_model_6000, test_case_dict_tppmi_6000_dynamic)\n",
    "''';"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To examine the quality of embedding alignment, we create a task to query equivalences across years.\n",
    "\n",
    "For example, given obama-2012, we want to query its equivalent word in 2002. As we know obama is the U.S. president in 2012; its equivalent in 2002 is bush, who was the U.S. president at that time. In this way, we create two testsets.\n",
    "\n",
    "All results are rounded to three decimal places."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cutoffs = [1, 3, 5, 10]\n",
    "list_of_types = [\"static\", \"dynamic\", \"all\"]\n",
    "\n",
    "list_of_data_cade = [[similarities_cade_static, test_data_1_static],\n",
    "                     [similarities_cade_dynamic, test_data_1_dynamic], [similarities_cade_all, test_data_1_all]]\n",
    "\n",
    "list_of_data_tppmi_500 = [[similarities_tppmi_500_static, test_data_1_static],\n",
    "                       [similarities_tppmi_500_dynamic, test_data_1_dynamic], [similarities_tppmi_500_all, test_data_1_all]]\n",
    "list_of_data_tppmi_1000 = [[similarities_tppmi_1000_static, test_data_1_static],\n",
    "                          [similarities_tppmi_1000_dynamic, test_data_1_dynamic], [similarities_tppmi_1000_all, test_data_1_all]]\n",
    "list_of_data_tppmi_2000 = [[similarities_tppmi_2000_static, test_data_1_static],\n",
    "                           [similarities_tppmi_2000_dynamic, test_data_1_dynamic], [similarities_tppmi_2000_all, test_data_1_all]]\n",
    "\n",
    "'''\n",
    "list_of_data_tppmi_4000 = [[similarities_tppmi_4000_static, test_data_1_static],\n",
    "                           [similarities_tppmi_4000_dynamic, test_data_1_dynamic], [similarities_tppmi_4000_all, test_data_1_all]]\n",
    "list_of_data_tppmi_6000 = [[similarities_tppmi_6000_static, test_data_1_static],\n",
    "                           [similarities_tppmi_6000_dynamic, test_data_1_dynamic], [similarities_tppmi_6000_all, test_data_1_all]]\n",
    "''';\n",
    "list_of_data_static = [[similarities_static_static, test_data_1_static],\n",
    "                       [similarities_static_dynamic, test_data_1_dynamic], [similarities_static_all, test_data_1_all]]\n",
    "\n",
    "config_dict_cade = {key: value for key, value in zip(list_of_types, list_of_data_cade)}\n",
    "config_dict_tppmi_500 = {key: value for key, value in zip(list_of_types, list_of_data_tppmi_500)}\n",
    "config_dict_tppmi_1000 = {key: value for key, value in zip(list_of_types, list_of_data_tppmi_1000)}\n",
    "config_dict_tppmi_2000 = {key: value for key, value in zip(list_of_types, list_of_data_tppmi_2000)}\n",
    "'''\n",
    "config_dict_tppmi_4000 = {key: value for key, value in zip(list_of_types, list_of_data_tppmi_4000)}\n",
    "config_dict_tppmi_6000 = {key: value for key, value in zip(list_of_types, list_of_data_tppmi_6000)}\n",
    "''';\n",
    "config_dict_static = {key: value for key, value in zip(list_of_types, list_of_data_static)}\n",
    "\n",
    "scores_cade = {key: dict() for key in list_of_types}\n",
    "scores_static = {key: dict() for key in list_of_types}\n",
    "scores_tppmi_500 = {key: dict() for key in list_of_types}\n",
    "scores_tppmi_1000 = {key: dict() for key in list_of_types}\n",
    "scores_tppmi_2000 = {key: dict() for key in list_of_types}\n",
    "'''\n",
    "scores_tppmi_4000 = {key: dict() for key in list_of_types}\n",
    "scores_tppmi_6000 = {key: dict() for key in list_of_types}\n",
    "''';"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean Reciprocal Rank (@10)\n",
    "\n",
    "The Mean Reciprocal Rank (MRR) is a statistical measure used to evaluate the performance of a system that returns a ranked list of responses to queries. It is the average of the reciprocal ranks of the first correct answer for each query, where the reciprocal rank is the inverse of the rank at which the first relevant answer is found.\n",
    "It is evaluated @10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TWEC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_cade.items()):\n",
    "    scores_cade[key][\"mrr@10\"] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MRR'), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Static Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_static.items()):\n",
    "    scores_static[key][\"mrr@10\"] = round(test_util.calculate_rank_metric_static(value[0], value[1], metric='MRR'), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TPPMI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_500.items()):\n",
    "    scores_tppmi_500[key][\"mrr@10\"] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MRR'), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_1000.items()):\n",
    "    scores_tppmi_1000[key][\"mrr@10\"] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MRR'), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_2000.items()):\n",
    "    scores_tppmi_2000[key][\"mrr@10\"] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MRR'), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "for key, value in tqdm(config_dict_tppmi_4000.items()):\n",
    "    scores_tppmi_4000[key][\"mrr@10\"] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MRR'), 3)\n",
    "    ''';"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "for key, value in tqdm(config_dict_tppmi_6000.items()):\n",
    "    scores_tppmi_6000[key][\"mrr@10\"] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MRR'), 3)\n",
    "    ''';"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean Precision (@K)\n",
    "\n",
    "As introduced by Yao et al.(2018) the MP@K is defined as such: consider the K words most similar to the query embedding for the given year. The Precision@K for a particular test i, represented as P@K[i], equals 1 if the target word appears within this set of K words; otherwise, it assumes a value of 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TWEC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_cade.items()):\n",
    "    for k in cutoffs:\n",
    "        score_key = f\"mp@{k}\"\n",
    "        scores_cade[key][score_key] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MP', k=k), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Static Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_static.items()):\n",
    "    for k in cutoffs:\n",
    "        score_key = f\"mp@{k}\"\n",
    "        scores_static[key][score_key] = round(test_util.calculate_rank_metric_static(value[0], value[1], metric='MP', k=k), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TPPMI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_500.items()):\n",
    "    for k in cutoffs:\n",
    "        score_key = f\"mp@{k}\"\n",
    "        scores_tppmi_500[key][score_key] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MP', k=k), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_1000.items()):\n",
    "    for k in cutoffs:\n",
    "        score_key = f\"mp@{k}\"\n",
    "        scores_tppmi_1000[key][score_key] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MP', k=k), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_2000.items()):\n",
    "    for k in cutoffs:\n",
    "        score_key = f\"mp@{k}\"\n",
    "        scores_tppmi_2000[key][score_key] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MP', k=k), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_4000.items()):\n",
    "    for k in cutoffs:\n",
    "        score_key = f\"mp@{k}\"\n",
    "        scores_tppmi_4000[key][score_key] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MP', k=k), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, value in tqdm(config_dict_tppmi_6000.items()):\n",
    "    for k in cutoffs:\n",
    "        score_key = f\"mp@{k}\"\n",
    "        scores_tppmi_6000[key][score_key] = round(test_util.calculate_rank_metric(value[0], value[1], metric='MP', k=k), 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_table_cade = pd.DataFrame(scores_cade).T\n",
    "score_table_static = pd.DataFrame(scores_static).T\n",
    "score_table_tppmi_500 = pd.DataFrame(scores_tppmi_500).T\n",
    "score_table_tppmi_1000 = pd.DataFrame(scores_tppmi_1000).T\n",
    "score_table_tppmi_2000 = pd.DataFrame(scores_tppmi_2000).T\n",
    "score_table_tppmi_4000 = pd.DataFrame(scores_tppmi_4000).T\n",
    "score_table_tppmi_6000 = pd.DataFrame(scores_tppmi_6000).T\n",
    "#score_table_tppmi_8000 = pd.DataFrame(scores_tppmi_8000).T\n",
    "print(\"Scores of TWEC\")\n",
    "display(score_table_cade)\n",
    "print(\"Scores of TPPMI (500 context-words)\")\n",
    "display(score_table_tppmi_500)\n",
    "print(\"Scores of TPPMI (1000 context-words)\")\n",
    "display(score_table_tppmi_1000)\n",
    "print(\"Scores of TPPMI (2000 context-words)\")\n",
    "display(score_table_tppmi_2000)\n",
    "print(\"Scores of TPPMI (4000 context-words)\")\n",
    "display(score_table_tppmi_4000)\n",
    "print(\"Scores of TPPMI (6000 context-words)\")\n",
    "display(score_table_tppmi_6000))\n",
    "print(\"Scores of Static Word2Vec (Baseline)\")\n",
    "display(score_table_static)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "score_table_cade['Model'] = 'TWEC'\n",
    "score_table_tppmi_500['Model'] = 'TPPMI (500 context-words)'\n",
    "score_table_tppmi_1000['Model'] = 'TPPMI (1000 context-words)'\n",
    "score_table_tppmi_2000['Model'] = 'TPPMI (2000 context-words)'\n",
    "score_table_static['Model'] = 'Static Word2Vec (Baseline)'\n",
    "\n",
    "merged_score_table = pd.concat([score_table_cade, score_table_tppmi_500,\n",
    "                                score_table_tppmi_1000, score_table_tppmi_2000, score_table_static], ignore_index=False)\n",
    "\n",
    "merged_score_table.set_index(['Model', merged_score_table.index], inplace=True)\n",
    "model_order = ['TWEC', 'TPPMI (500 context-words)', 'TPPMI (1000 context-words)', 'TPPMI (2000 context-words)', 'Static Word2Vec (Baseline)']\n",
    "merged_score_table = merged_score_table.reindex(model_order, level='Model')\n",
    "merged_score_table = merged_score_table.round(3)\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)  # Replace None with a large number if the table is too long\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "merged_score_table''';"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----------------------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_table_dir = Path(\"../../data/results/nyt-data\")\n",
    "score_table_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Saving the CADE score table to CSV\n",
    "score_table_cade.to_csv(score_table_dir / \"score_table_cade.csv\", index=True)\n",
    "\n",
    "# Saving the TPPMI score table to CSV\n",
    "score_table_tppmi_500.to_csv(score_table_dir / 'score_table_tppmi_500.csv', index=True)\n",
    "score_table_tppmi_1000.to_csv(score_table_dir / 'score_table_tppmi_1000.csv', index=True)\n",
    "score_table_tppmi_2000.to_csv(score_table_dir / 'score_table_tppmi_2000.csv', index=True)\n",
    "score_table_tppmi_4000.to_csv(score_table_dir / 'score_table_tppmi_4000.csv', index=True)\n",
    "score_table_tppmi_6000.to_csv(score_table_dir / 'score_table_tppmi_6000.csv', index=True)\n",
    "\n",
    "# Saving the Static Word2Vec (Baseline) score table to CSV\n",
    "score_table_static.to_csv(score_table_dir / 'score_table_static.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scores from Memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_tables = test_util.load_score_tables(score_table_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_tables.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, score_table in score_tables.items():\n",
    "    if \"500\" in name:\n",
    "        continue\n",
    "    print(f\"Scores for the model: {name.split('table_')[-1].capitalize()}\")\n",
    "    display(score_table)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
